{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a979ed0",
   "metadata": {},
   "source": [
    "## Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd133157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of transformers to simulate\n",
    "NUM_TRANSFORMERS = 10\n",
    "\n",
    "# Number of records to generate per batch\n",
    "RECORDS_PER_BATCH = 50\n",
    "\n",
    "# Stream interval in seconds (time between batches)\n",
    "STREAM_INTERVAL = 5\n",
    "\n",
    "# Anomaly settings\n",
    "ANOMALY_PROBABILITY = 0.05  # 5% chance of anomaly per reading\n",
    "ANOMALY_TEMP_MIN = 130      # Anomaly temperature range\n",
    "ANOMALY_TEMP_MAX = 150\n",
    "\n",
    "# Azure Service Bus / Fabric EventStream settings\n",
    "SERVICEBUS_CONNECTION_STRING = \"\"  # Add your connection string here\n",
    "EVENTSTREAM_NAME = \"\"  # Add your EventStream/topic name here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260d964",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b32f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "from azure.servicebus import ServiceBusClient, ServiceBusMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a31495",
   "metadata": {},
   "source": [
    "## Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49318a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TransformerStreamGenerator\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb480b7c",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab9719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transformer_id():\n",
    "    \"\"\"Generate an 8-character alphanumeric transformer ID\"\"\"\n",
    "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=8))\n",
    "\n",
    "def generate_transformer_ids(num_transformers):\n",
    "    \"\"\"Generate a list of unique transformer IDs\"\"\"\n",
    "    return [generate_transformer_id() for _ in range(num_transformers)]\n",
    "\n",
    "class TemperatureSimulator:\n",
    "    \"\"\"Simulate temperature readings with gradual changes\"\"\"\n",
    "    def __init__(self, min_temp=60, max_temp=120, anomaly_probability=0.05, anomaly_min=130, anomaly_max=150):\n",
    "        self.min_temp = min_temp\n",
    "        self.max_temp = max_temp\n",
    "        self.anomaly_probability = anomaly_probability\n",
    "        self.anomaly_min = anomaly_min\n",
    "        self.anomaly_max = anomaly_max\n",
    "        # Initialize with random temperature for each transformer\n",
    "        self.current_temps = {}\n",
    "    \n",
    "    def get_temperature(self, transformer_id):\n",
    "        \"\"\"Get temperature for a transformer with gradual changes and occasional anomalies\"\"\"\n",
    "        if transformer_id not in self.current_temps:\n",
    "            # Initialize with a random temperature in the middle range\n",
    "            self.current_temps[transformer_id] = random.randint(80, 100)\n",
    "        \n",
    "        # Check for anomaly\n",
    "        if random.random() < self.anomaly_probability:\n",
    "            # Return anomaly temperature without updating current temp\n",
    "            return random.randint(self.anomaly_min, self.anomaly_max)\n",
    "        \n",
    "        # Make small random changes (-5 to +5 degrees)\n",
    "        change = random.randint(-5, 5)\n",
    "        new_temp = self.current_temps[transformer_id] + change\n",
    "        \n",
    "        # Keep within bounds using Python's built-in min/max\n",
    "        if new_temp < self.min_temp:\n",
    "            new_temp = self.min_temp\n",
    "        elif new_temp > self.max_temp:\n",
    "            new_temp = self.max_temp\n",
    "            \n",
    "        self.current_temps[transformer_id] = new_temp\n",
    "        \n",
    "        return new_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165182ad",
   "metadata": {},
   "source": [
    "## Initialize Transformers and Temperature Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd51e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate transformer IDs\n",
    "transformer_ids = generate_transformer_ids(NUM_TRANSFORMERS)\n",
    "print(f\"Generated {len(transformer_ids)} transformer IDs:\")\n",
    "for tid in transformer_ids:\n",
    "    print(f\"  - {tid}\")\n",
    "\n",
    "# Initialize temperature simulator with anomaly settings\n",
    "temp_simulator = TemperatureSimulator(\n",
    "    anomaly_probability=ANOMALY_PROBABILITY,\n",
    "    anomaly_min=ANOMALY_TEMP_MIN,\n",
    "    anomaly_max=ANOMALY_TEMP_MAX\n",
    ")\n",
    "print(f\"\\nAnomaly detection configured: {ANOMALY_PROBABILITY*100}% probability, temp range {ANOMALY_TEMP_MIN}-{ANOMALY_TEMP_MAX}°F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c15bba4",
   "metadata": {},
   "source": [
    "## Generate Stream Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad54cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stream_batch(transformer_ids, temp_simulator, num_records):\n",
    "    \"\"\"Generate a batch of transformer readings\"\"\"\n",
    "    records = []\n",
    "    \n",
    "    for _ in range(num_records):\n",
    "        # Select a random transformer\n",
    "        transformer_id = random.choice(transformer_ids)\n",
    "        \n",
    "        # Generate reading\n",
    "        record = {\n",
    "            \"DateTime\": datetime.now(timezone.utc).isoformat(),\n",
    "            \"TransformerID\": transformer_id,\n",
    "            \"Temperature\": temp_simulator.get_temperature(transformer_id),\n",
    "            \"Voltage\": random.randint(220, 280)\n",
    "        }\n",
    "        records.append(record)\n",
    "    \n",
    "    return records\n",
    "\n",
    "def stream_to_json(records):\n",
    "    \"\"\"Convert records to JSON string\"\"\"\n",
    "    return json.dumps(records, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2c2704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test EventStream connectivity\n",
    "if SERVICEBUS_CONNECTION_STRING and EVENTSTREAM_NAME:\n",
    "    # Generate a small test batch\n",
    "    test_eventstream_batch = generate_stream_batch(transformer_ids, temp_simulator, 5)\n",
    "    \n",
    "    # Send to EventStream\n",
    "    print(\"Testing EventStream connection...\")\n",
    "    sent_count = send_to_eventstream(test_eventstream_batch, SERVICEBUS_CONNECTION_STRING, EVENTSTREAM_NAME)\n",
    "    print(f\"Successfully sent {sent_count} records to EventStream\")\n",
    "else:\n",
    "    print(\"Please configure SERVICEBUS_CONNECTION_STRING and EVENTSTREAM_NAME in the configuration cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b53f3c",
   "metadata": {},
   "source": [
    "## Test EventStream Connection\n",
    "\n",
    "Test sending a small batch to Fabric EventStream. Make sure to set your connection string and EventStream name in the configuration cell first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c6676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventStreamSender:\n",
    "    \"\"\"Send data to Fabric EventStream via Azure Service Bus\"\"\"\n",
    "    \n",
    "    def __init__(self, connection_string, eventstream_name):\n",
    "        \"\"\"\n",
    "        Initialize the EventStream sender\n",
    "        \n",
    "        Args:\n",
    "            connection_string: Azure Service Bus connection string\n",
    "            eventstream_name: Name of the EventStream/topic\n",
    "        \"\"\"\n",
    "        self.connection_string = connection_string\n",
    "        self.eventstream_name = eventstream_name\n",
    "        self.client = None\n",
    "        self.sender = None\n",
    "        \n",
    "    def connect(self):\n",
    "        \"\"\"Establish connection to Service Bus\"\"\"\n",
    "        try:\n",
    "            self.client = ServiceBusClient.from_connection_string(\n",
    "                conn_str=self.connection_string,\n",
    "                logging_enable=True\n",
    "            )\n",
    "            self.sender = self.client.get_topic_sender(topic_name=self.eventstream_name)\n",
    "            print(f\"Connected to EventStream: {self.eventstream_name}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to EventStream: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def send_batch(self, records):\n",
    "        \"\"\"\n",
    "        Send a batch of records to EventStream\n",
    "        \n",
    "        Args:\n",
    "            records: List of record dictionaries\n",
    "            \n",
    "        Returns:\n",
    "            Number of records sent successfully\n",
    "        \"\"\"\n",
    "        if not self.sender:\n",
    "            print(\"Not connected. Call connect() first.\")\n",
    "            return 0\n",
    "        \n",
    "        try:\n",
    "            # Create a batch of messages\n",
    "            message_batch = self.sender.create_message_batch()\n",
    "            \n",
    "            sent_count = 0\n",
    "            for record in records:\n",
    "                # Convert record to JSON string\n",
    "                message_body = json.dumps(record)\n",
    "                message = ServiceBusMessage(message_body)\n",
    "                \n",
    "                try:\n",
    "                    message_batch.add_message(message)\n",
    "                    sent_count += 1\n",
    "                except ValueError:\n",
    "                    # Batch is full, send it and create a new batch\n",
    "                    self.sender.send_messages(message_batch)\n",
    "                    message_batch = self.sender.create_message_batch()\n",
    "                    message_batch.add_message(message)\n",
    "                    sent_count += 1\n",
    "            \n",
    "            # Send any remaining messages\n",
    "            if len(message_batch) > 0:\n",
    "                self.sender.send_messages(message_batch)\n",
    "            \n",
    "            return sent_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error sending batch: {e}\")\n",
    "            return 0\n",
    "    \n",
    "    def send_single(self, record):\n",
    "        \"\"\"\n",
    "        Send a single record to EventStream\n",
    "        \n",
    "        Args:\n",
    "            record: Record dictionary\n",
    "            \n",
    "        Returns:\n",
    "            True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        if not self.sender:\n",
    "            print(\"Not connected. Call connect() first.\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            message_body = json.dumps(record)\n",
    "            message = ServiceBusMessage(message_body)\n",
    "            self.sender.send_messages(message)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error sending message: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close the connection to Service Bus\"\"\"\n",
    "        try:\n",
    "            if self.sender:\n",
    "                self.sender.close()\n",
    "            if self.client:\n",
    "                self.client.close()\n",
    "            print(\"Connection closed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error closing connection: {e}\")\n",
    "\n",
    "def send_to_eventstream(records, connection_string, eventstream_name):\n",
    "    \"\"\"\n",
    "    Helper function to send records to EventStream\n",
    "    \n",
    "    Args:\n",
    "        records: List of record dictionaries\n",
    "        connection_string: Azure Service Bus connection string\n",
    "        eventstream_name: Name of the EventStream/topic\n",
    "        \n",
    "    Returns:\n",
    "        Number of records sent successfully\n",
    "    \"\"\"\n",
    "    sender = EventStreamSender(connection_string, eventstream_name)\n",
    "    if sender.connect():\n",
    "        sent_count = sender.send_batch(records)\n",
    "        sender.close()\n",
    "        return sent_count\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdc47ec",
   "metadata": {},
   "source": [
    "## Send Data to Fabric EventStream\n",
    "\n",
    "Functions to send generated data to Azure Service Bus / Fabric EventStream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091fcfdd",
   "metadata": {},
   "source": [
    "## Generate Single Batch (Test)\n",
    "\n",
    "Generate and display a single batch of records to verify the output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe4c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a test batch\n",
    "test_batch = generate_stream_batch(transformer_ids, temp_simulator, 10)\n",
    "print(\"Sample batch of 10 records:\")\n",
    "print(stream_to_json(test_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1806dc73",
   "metadata": {},
   "source": [
    "## Create PySpark DataFrame from Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05844614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"DateTime\", StringType(), False),\n",
    "    StructField(\"TransformerID\", StringType(), False),\n",
    "    StructField(\"Temperature\", IntegerType(), False),\n",
    "    StructField(\"Voltage\", IntegerType(), False)\n",
    "])\n",
    "\n",
    "# Create DataFrame from test batch\n",
    "df = spark.createDataFrame(test_batch, schema=schema)\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c21b5a",
   "metadata": {},
   "source": [
    "## Continuous Stream Generation\n",
    "\n",
    "Generate continuous batches of transformer data. This cell will run indefinitely until manually stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f93901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous stream generation (run until stopped)\n",
    "print(f\"Starting continuous stream generation...\")\n",
    "print(f\"Generating {RECORDS_PER_BATCH} records every {STREAM_INTERVAL} seconds\")\n",
    "print(f\"Press 'Stop' to terminate\\n\")\n",
    "\n",
    "batch_count = 0\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        batch_count += 1\n",
    "        \n",
    "        # Generate batch\n",
    "        batch = generate_stream_batch(transformer_ids, temp_simulator, RECORDS_PER_BATCH)\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = spark.createDataFrame(batch, schema=schema)\n",
    "        \n",
    "        # Display summary\n",
    "        print(f\"\\n=== Batch {batch_count} - {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')} ===\")\n",
    "        print(f\"Records generated: {df.count()}\")\n",
    "        df.groupBy(\"TransformerID\").agg(\n",
    "            count(\"*\").alias(\"RecordCount\"),\n",
    "            avg(\"Temperature\").alias(\"AvgTemperature\"),\n",
    "            avg(\"Voltage\").alias(\"AvgVoltage\")\n",
    "        ).show()\n",
    "        \n",
    "        # Optional: Show sample records\n",
    "        print(\"Sample records:\")\n",
    "        df.show(5, truncate=False)\n",
    "        \n",
    "        # Wait before next batch\n",
    "        time.sleep(STREAM_INTERVAL)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\nStream generation stopped. Total batches generated: {batch_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e487c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous stream generation with EventStream integration\n",
    "if not SERVICEBUS_CONNECTION_STRING or not EVENTSTREAM_NAME:\n",
    "    print(\"ERROR: Please configure SERVICEBUS_CONNECTION_STRING and EVENTSTREAM_NAME first!\")\n",
    "else:\n",
    "    print(f\"Starting continuous stream to EventStream...\")\n",
    "    print(f\"Generating {RECORDS_PER_BATCH} records every {STREAM_INTERVAL} seconds\")\n",
    "    print(f\"Press 'Stop' to terminate\\n\")\n",
    "    \n",
    "    # Connect to EventStream\n",
    "    eventstream_sender = EventStreamSender(SERVICEBUS_CONNECTION_STRING, EVENTSTREAM_NAME)\n",
    "    if not eventstream_sender.connect():\n",
    "        print(\"Failed to connect to EventStream. Exiting.\")\n",
    "    else:\n",
    "        batch_count = 0\n",
    "        total_sent = 0\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                batch_count += 1\n",
    "                \n",
    "                # Generate batch\n",
    "                batch = generate_stream_batch(transformer_ids, temp_simulator, RECORDS_PER_BATCH)\n",
    "                \n",
    "                # Send to EventStream\n",
    "                sent_count = eventstream_sender.send_batch(batch)\n",
    "                total_sent += sent_count\n",
    "                \n",
    "                # Create DataFrame for display\n",
    "                df = spark.createDataFrame(batch, schema=schema)\n",
    "                \n",
    "                # Display summary\n",
    "                print(f\"\\n=== Batch {batch_count} - {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')} ===\")\n",
    "                print(f\"Records generated: {df.count()}\")\n",
    "                print(f\"Records sent to EventStream: {sent_count}\")\n",
    "                print(f\"Total records sent: {total_sent}\")\n",
    "                \n",
    "                df.groupBy(\"TransformerID\").agg(\n",
    "                    count(\"*\").alias(\"RecordCount\"),\n",
    "                    avg(\"Temperature\").alias(\"AvgTemperature\"),\n",
    "                    avg(\"Voltage\").alias(\"AvgVoltage\")\n",
    "                ).show()\n",
    "                \n",
    "                # Check for anomalies in this batch\n",
    "                anomalies = df.filter(col(\"Temperature\") > 120)\n",
    "                if anomalies.count() > 0:\n",
    "                    print(f\"⚠️  ANOMALIES DETECTED: {anomalies.count()} records\")\n",
    "                    anomalies.show(truncate=False)\n",
    "                \n",
    "                # Wait before next batch\n",
    "                time.sleep(STREAM_INTERVAL)\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\nStream generation stopped.\")\n",
    "            print(f\"Total batches generated: {batch_count}\")\n",
    "            print(f\"Total records sent: {total_sent}\")\n",
    "        finally:\n",
    "            eventstream_sender.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05de2907",
   "metadata": {},
   "source": [
    "## Continuous Stream to EventStream\n",
    "\n",
    "Generate continuous batches and send them to Fabric EventStream. This cell will run indefinitely until manually stopped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181b3df0",
   "metadata": {},
   "source": [
    "## Export Single Batch to JSON File\n",
    "\n",
    "Generate a single batch and save it to a JSON file for testing or integration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a908964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batch and save to file\n",
    "output_batch = generate_stream_batch(transformer_ids, temp_simulator, RECORDS_PER_BATCH)\n",
    "output_filename = f\"transformer_stream_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "\n",
    "with open(output_filename, 'w') as f:\n",
    "    json.dump(output_batch, f, indent=2)\n",
    "\n",
    "print(f\"Batch exported to: {output_filename}\")\n",
    "print(f\"Records: {len(output_batch)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
